/* File:        $Id$
 * Revision:    $Revision$
 * Author:      $Author$
 * Date:        $Date$
 *
 * The Netarchive Suite - Software to harvest and preserve websites
 * Copyright 2004-2009 Det Kongelige Bibliotek and Statsbiblioteket, Denmark
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 2.1 of the License, or (at your option) any later version.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
 */
package dk.netarkivet.harvester.datamodel;

import java.io.BufferedReader;
import java.io.File;
import java.io.IOException;
import java.io.ObjectInputStream;
import java.io.ObjectOutputStream;
import java.io.Serializable;
import java.io.StringReader;
import java.net.MalformedURLException;
import java.net.URL;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.TreeSet;
import java.util.regex.Pattern;

import gnu.inet.encoding.IDNA;
import gnu.inet.encoding.IDNAException;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.archive.crawler.deciderules.MatchesListRegExpDecideRule;
import org.dom4j.Document;
import org.dom4j.Element;
import org.dom4j.Node;

import dk.netarkivet.common.exceptions.ArgumentNotValid;
import dk.netarkivet.common.exceptions.IOFailure;
import dk.netarkivet.common.exceptions.IllegalState;
import dk.netarkivet.common.exceptions.PermissionDenied;
import dk.netarkivet.common.exceptions.UnknownID;
import dk.netarkivet.common.utils.DomainUtils;
import dk.netarkivet.common.utils.NotificationsFactory;
import dk.netarkivet.common.utils.Settings;
import dk.netarkivet.common.utils.StringUtils;
import dk.netarkivet.harvester.HarvesterSettings;


/**
 * This class represents one job to run by Heritrix.
 * It's based on a number of configurations all based on the same order.xml
 * and at most one configuration for each domain.
 * Each job consists of configurations of the approximate same size; that is
 * the difference in expectation from the smallest configuration to the
 * largest configuration is within a factor of each other defined as
 * limMaxRelSize (although differences smaller than limMinAbsSize are ignored)
 * There is a limit limMaxTotalSize on the total size of the job in objects.
 *
 * A job may also be limited on bytes or objects, defined either by the
 * configurations in the job or the harvest definition the job is generated by.
 *
 * The job contains the order file, the seedlist and the current status of the
 * job, as well as the ID of the harvest definition that defined it and names
 * of all the configurations it is based on.
 */
public class Job implements Serializable {
    private transient Log log = LogFactory.getLog(getClass());

    //Persistent fields stored in and read from DAO
    /** The persistent ID of this job. */
    private Long jobID;
    /** The Id of the harvestdefinition, that generated this job. */
    private Long origHarvestDefinitionID;
    /** The status of the job. See the JobStatus class for the possible states. */
    private JobStatus status;
    /**
     * The priority of this job.
     */
    private JobPriority priority;
    /**
     * Overrides the individual configurations maximum setting for objects
     * retrieved from a domain when set to a positive value.
     */
    private long forceMaxObjectsPerDomain =
            Constants.HERITRIX_MAXOBJECTS_INFINITY;
    /**
     * Overrides the individual configurations maximum setting for bytes
     * retrieved from a domain when set to other than -1.
     */
    private long forceMaxBytesPerDomain = Constants.HERITRIX_MAXBYTES_INFINITY;
    /** The name of the harvest template used by the job. */
    private String orderXMLname;
    /** The harvest template used by the job. */
    private Document orderXMLdoc;
    /** The list of Heritrix settings files. */
    private File[] settingsXMLfiles;
    /** The corresponding Dom4j Documents for these files. */
    private Document[] settingsXMLdocs;

    /**
     * A set of seeds involved in this job.
     * Outside the SetSeedList() method, the set of seeds is updated
     * in the addConfiguration() method.
     */
    private Set<String> seedListSet = new HashSet<String>();
    /** Which run of the harvest definition this is. */
    private int harvestNum;
    /** Errors during harvesting. */
    private String harvestErrors;
    /** Details about errors during harvesting. */
    private String harvestErrorDetails;
    /** Errors during upload of the harvested data. */
    private String uploadErrors;
    /** Details about errors during upload of the harvested data. */
    private String uploadErrorDetails;
    /** The starting point of the job. */
    private Date actualStart;
    /** The ending point of the job. */
    private Date actualStop;
    /** The time when this job was submitted. */
    private Date submittedDate;
    
    /**
     * Edition is used by the DAO to keep track of changes.
     */
    private long edition = -1;
    
    /**
     * Resubmitted as the Job with this ID.
     * If null, this job has not been resubmitted.
     */
    private Long resubmittedAsJobWithID;
    
    /**
     * A map (domainName, domainConfigurationName), must be accessible in order
     * to update job information (see Ass. 2.4.3)
     */
    private Map<String, String> domainConfigurationMap;
    /** A hint to the DAO that configurations have changed.
     * Since configurations are large, the DAO can use that this is false
     * to avoid updating the config list.  The DAO can set it to false after
     * saving configurations.
     */
    boolean configsChanged = false;


    //Intermediate fields, non-persistent and only used while building objects

    /**
     * Whether the maxObjects field was defined by the harvest definition or the
     * configuration limit. This is deciding for whether we accept smaller
     * configurations or not when building jobs. True means the limit is defined
     * by the configuration, false means that it is defined by the 
     * harvest definition.
     */
    private boolean configurationSetsObjectLimit;
    
    /**
     * Whether the maxBytes field was defined by the harvest definition or the
     * configuration limit. This is deciding for whether we accept smaller
     * configurations or not when building jobs. True means the limit is defined
     * by the configuration, false means by the harvest definition.
     */
    private boolean configurationSetsByteLimit;

    /**
     * The lowest number of objects expected by a configuration.
     */
    private long minCountObjects;

    /**
     * The highest number of objects expected by a configuration.
     */
    private long maxCountObjects;

    /**
     * The total number of objects expected by all added configurations.
     */
    private long totalCountObjects;

    /** If true, this job object is still undergoing changes due to having
     * more configurations added.  When set to false, the object is no longer
     * considered immutable except for updating status.
     *
     * Jobs loaded from the DAO are never under construction anymore.
     */
    private boolean underConstruction = true;

    //Constants

    //Note: The following constants are intentionally left non-static for easy
    //unit testing

    /**
     * Job limits read from settings during construction.
     */
    private final long LIM_MAX_REL_SIZE
            = Long.parseLong(
            Settings.get(HarvesterSettings.JOBS_MAX_RELATIVE_SIZE_DIFFERENCE));
    private final long LIM_MIN_ABS_SIZE
            = Long.parseLong(
            Settings.get(HarvesterSettings.JOBS_MIN_ABSOLUTE_SIZE_DIFFERENCE));
    private final long LIM_MAX_TOTAL_SIZE
            = Long.parseLong(Settings.get(
                    HarvesterSettings.JOBS_MAX_TOTAL_JOBSIZE));

    private static final int BYTES_PER_HERITRIX_BYTELIMIT_UNIT = 1024;

    /**
     * Package private constructor for common initialisation.
     *
     * @param harvestID                the id of the harvestdefinition
     * @param cfg                      the configuration to base the Job on
     * @param priority                 the priority of the job
     * @param forceMaxObjectsPerDomain the maximum number of objects harvested
     *                                 from a domain, overrides individual
     *                                 configuration settings. 
     *                                 -1 means no limit
     * @param forceMaxBytesPerDomain The maximum number of objects harvested
     * from a domain, or -1 for no limit.
     * @param harvestNum               the run number of the harvest definition
     * @throws ArgumentNotValid if cfg or priority is null or harvestID is
     *                          invalid, or if any limit < -1
     * @throws UnknownID        If the priority is invalid.
     */
    Job(Long harvestID, DomainConfiguration cfg, JobPriority priority,
        long forceMaxObjectsPerDomain, long forceMaxBytesPerDomain,
        int harvestNum) throws ArgumentNotValid {
        ArgumentNotValid.checkNotNull(cfg, "cfg");
        ArgumentNotValid.checkNotNull(harvestID, "harvestID");
        ArgumentNotValid.checkNotNegative(harvestID, "harvestID");
        ArgumentNotValid.checkNotNull(priority, "priority");
        if (forceMaxObjectsPerDomain < -1) {
            String msg
                = "forceMaxObjectsPerDomain must be either -1 or positive";
            log.debug(msg);
            throw new ArgumentNotValid(msg);
        }
        if (forceMaxBytesPerDomain < -1) {
            String msg = "forceMaxBytesPerDomain must be either -1 or positive";
            log.debug(msg);
            throw new ArgumentNotValid(msg);
        }

        if (forceMaxBytesPerDomain == 0L) {
            String msg = "forceMaxBytesPerDomain should probably not be 0."
                + "Means 0 bytes downloaded per domain";
            log.warn(msg);
        }

        if (forceMaxObjectsPerDomain == 0L) {
            String msg = "forceMaxObjectsPerDomain should probably not be 0."
                + "Means 0 objects downloaded per domain";
            log.warn(msg);
        }

        // setup initial members
        domainConfigurationMap = new HashMap<String, String>();
        origHarvestDefinitionID = harvestID;
        orderXMLname = cfg.getOrderXmlName();
        orderXMLdoc = TemplateDAO.getInstance().read(
                cfg.getOrderXmlName()).getTemplate();

        this.priority = priority;

        long maxObjects = NumberUtils.minInf(
                forceMaxObjectsPerDomain, cfg.getMaxObjects());        
        setForceMaxObjectsPerDomain(maxObjects);
        configurationSetsObjectLimit = (maxObjects != forceMaxObjectsPerDomain);

        long maxBytes = NumberUtils.minInf(
                forceMaxBytesPerDomain, cfg.getMaxBytes());        
        setMaxBytesPerDomain(maxBytes);
        configurationSetsByteLimit = (maxBytes != forceMaxBytesPerDomain);

        long expectation = cfg.getExpectedNumberOfObjects(
                        forceMaxObjectsPerDomain, forceMaxBytesPerDomain);
        maxCountObjects = expectation;
        minCountObjects = expectation;
        this.harvestNum = harvestNum;

        // ingest the configuration just as any other configuration
        // The seedlist, configuration map, and max/min limits are changed
        // as result of this method-call.
        addConfiguration(cfg);
        addGlobalCrawlerTraps();
        status = JobStatus.NEW;
    }

    /** Create a new Job object from basic information storable in the DAO.
     *
     * @param harvestID                the id of the harvestdefinition
     * @param configurations           the configurations to base the Job on
     * @param priority                 the priority of the job
     * @param forceMaxObjectsPerDomain the maximum number of objects harvested
     *                                 from a domain, overrides individual
     *                                 configuration settings. 0 means no limit.
     * @param forceMaxBytesPerDomain The maximum number of objects harvested
     * from a domain, or -1 for no limit.
     * @param status                   the current status of the job.
     * @param orderXMLname             the name of the order template used.
     * @param orderXMLdoc              the (possibly modified) template
     * @param seedlist                 the combined seedlist from all configs.
     * @param harvestNum               the run number of the harvest definition
     */
    Job(Long harvestID, Map<String, String> configurations,
            JobPriority priority,
            long forceMaxObjectsPerDomain, long forceMaxBytesPerDomain,
            JobStatus status,
            String orderXMLname,
            Document orderXMLdoc, String seedlist, int harvestNum) {
        origHarvestDefinitionID = harvestID;
        domainConfigurationMap = configurations;
        this.priority = priority;

        this.forceMaxBytesPerDomain = forceMaxBytesPerDomain;
        this.forceMaxObjectsPerDomain = forceMaxObjectsPerDomain;
        this.status = status;
        this.orderXMLname = orderXMLname;
        this.orderXMLdoc = orderXMLdoc;
        this.setSeedList(seedlist);
        this.harvestNum = harvestNum;

        underConstruction = false;
    }

    /**
     * Create new Job configured according to the
     * properties of the supplied DomainConfiguration.
     *
     * @param harvestID the id of the harvestdefinition
     * @param cfg       the configuration to base the Job on
     * @param harvestNum Which run of the harvest definition this is.
     * @return newly created Job.
     * @throws ArgumentNotValid if cfg is null or harvestID is invalid
     */
    public static Job createJob(Long harvestID, DomainConfiguration cfg,
            int harvestNum) {
        // Use -1 to indicate no limits for max objects and max bytes.
        return new Job(harvestID, cfg, JobPriority.HIGHPRIORITY,
                Constants.HERITRIX_MAXOBJECTS_INFINITY,
                Constants.HERITRIX_MAXBYTES_INFINITY, harvestNum);
    }

    /**
     * Create new instance of Job suitable for snapshot harvesting.
     * This job is configured according to the
     * properties of the supplied DomainConfiguration.
     * The maximum number of objects retrieved from all domains added to
     * this job is determined by maxObjectsPerDomain, regardless of the
     * configuration settings, that are overridden.
     *
     * @param harvestID           the id of the harvestdefinition
     * @param cfg                 the configuration to base the Job on
     * @param maxObjectsPerDomain the maximum number of objects to harvest from
     *                            a domain, overrides individual configuration
     *                            settings unless the domain has overrideLimits
     *                            set.  0 means no limit.
     * @param maxBytesPerDomain the maximum number of bytes to harvest from a
     *                            domain, overrides individual configuration
     *                            settings unless the domain has overrideLimits
     *                            set.  -1 means no limit.
     * @param harvestNum          Which run of the harvest definition this is
     *                           (should always be 1).
     * @return SnapShotJob
     * @throws ArgumentNotValid if cfg is null or harvestID is invalid
     */
    public static Job createSnapShotJob(Long harvestID, DomainConfiguration cfg,
                                        long maxObjectsPerDomain,
                                        long maxBytesPerDomain, int harvestNum)
            throws ArgumentNotValid {
        return new Job(harvestID, cfg, JobPriority.LOWPRIORITY,
                maxObjectsPerDomain, maxBytesPerDomain, harvestNum);
    }

    /**
     *  Reads a list of all active global crawler trap expressions from the
     * database and adds them to the crawl template for this job.
     */
    private void addGlobalCrawlerTraps() {
        GlobalCrawlerTrapListDBDAO dao =
                GlobalCrawlerTrapListDBDAO.getInstance();
        editOrderXMLAddCrawlerTraps(Constants.GLOBAL_CRAWLER_TRAPS_ELEMENT_NAME,
                                    dao.getAllActiveTrapExpressions());
    }

    /**
     * Adds a configuration to this Job.
     * Seedlists and settings are updated accordingly.
     *
     * @param cfg the configuration to add
     * @throws ArgumentNotValid if cfg is null or cfg uses a
     *                          different orderxml than this job
     *                          or if this job already contains a configuration
     *                          associated with domain of configuration cfg.
     */
    public void addConfiguration(DomainConfiguration cfg) {
        ArgumentNotValid.checkNotNull(cfg, "cfg");

        log.trace("Adding configuration '" + cfg.toString() + "' to job '"
                  + cfg.getName() + "'");

        if (!underConstruction) {
            final String msg = "Cannot modify job "
                    + this + " as it is no longer under construction";
            log.debug(msg);
            throw new IllegalState(msg);
        }

        // Will accept unacceptable configurations if the map is empty so far
        // This allows configurations that exceed the normal max number of
        // objects
        if (!canAccept(cfg) && !domainConfigurationMap.isEmpty()) {
            throw new ArgumentNotValid("This job cannot accept the "
                                       + "configuration '" + cfg + "'");
        }

        // Check orderxml-name
        if (!cfg.getOrderXmlName().equals(getOrderXMLName())) {
            throw new ArgumentNotValid("Job requires the orderxml file:'"
                    + getOrderXMLName() + "' not:'" + cfg.getOrderXmlName()
                    + "' used by the configuration:'" + cfg.getName());
        }

        //Add configuration in map
        domainConfigurationMap.put(cfg.getDomain().getName(), cfg.getName());

        // Add the seeds from the configuration to the Job seeds.
        // Take care of duplicates.
        for (Iterator<SeedList> itt = cfg.getSeedLists(); itt.hasNext(); ) {
            SeedList seed = itt.next();
            List<String> seeds = seed.getSeeds();
            for (String seedUrl: seeds) {
                seedListSet.add(seedUrl); // duplicates is silently ignored

                //TODO remove when heritrix implements this functionality
                //try to convert a seed into a Internationalized Domain Name
                try {
                    String seedASCII = seedUrl;
                    // It is rare to see these seeds, but they need to be
                    // correctly idnaized
                    if (seedUrl.contains(":") || seedUrl.contains("/")) {
                        String normalizedUrl = seedUrl;
                        if (!normalizedUrl.matches("^[a-zA-Z]+:.*")) {
                            // If no protocol is given, assume http
                            normalizedUrl = "http://" + normalizedUrl;
                        }
                        URL url = new URL(normalizedUrl);
                        String domainName = url.getHost();
                        String domainNameASCII = IDNA.toASCII(domainName);
                        if (!domainName.equals(domainNameASCII)) {
                            // If the domain name changed, replace that in the
                            // seed.
                            seedASCII = seedUrl.replaceFirst(
                                    Pattern.quote(domainName),
                                    domainNameASCII);
                        }
                    } else {
                        seedASCII = IDNA.toASCII(seedUrl);
                    }
                    if (!seedASCII.equals(seedUrl)) {
                        log.trace("Converted " + seedUrl + " to " + seedASCII);
                        // Note that duplicates is silently ignored
                        seedListSet.add(seedASCII);
                    }
                } catch (IDNAException e) {
                    log.trace("Cannot convert seed "
                              + seedUrl + " to ASCII", e);
                } catch (MalformedURLException e) {
                    log.trace("Cannot convert seed "
                              + seedUrl + " to ASCII", e);
                }
            }
        }

        editOrderXMLAddPerDomainCrawlerTraps(cfg.getDomain());

        //TODO update limits in settings files - see also bug 269

        // Update estimates of job size
        long expectation
                = cfg.getExpectedNumberOfObjects(forceMaxObjectsPerDomain,
                        forceMaxBytesPerDomain);
        maxCountObjects = Math.max(expectation, maxCountObjects);
        minCountObjects = Math.min(expectation, minCountObjects);
        totalCountObjects += expectation;

        configsChanged = true;

        assert (maxCountObjects >= minCountObjects) : "basic invariant";
    }

    /** Updates this jobs order.xml to include a MatchesListRegExpDecideRule
     *  for each crawlertrap associated with for the given domain.
     *
     * The added nodes have the form
     *
     * <newObject name="domain.dk"
     *      class="org.archive.crawler.deciderules.MatchesListRegExpDecideRule">
     *       <string name="decision">REJECT</string>
     *       <string name="list-logic">OR</string>
     *       <stringList name="regexp-list">
     *          <string>theFirstRegexp</string>
     *          <string>theSecondRegexp</string>
     *       </stringList> 
     *     </newObject>
     *
     * @param d The domain for which to generate crawler trap deciderules
     * @throws IllegalState
     *          If unable to update order.xml due to wrong order.xml format
     */
    private void editOrderXMLAddPerDomainCrawlerTraps(Domain d) {
        //Get the regexps to exclude
        List<String> crawlerTraps = d.getCrawlerTraps();
        String elementName = d.getName();
        editOrderXMLAddCrawlerTraps(elementName, crawlerTraps);
    }

    /**
     * Method to add a list of crawler traps with a given element name. It is
     * used both to add per-domain traps and global traps.
     * @param elementName The name of the added element.
     * @param crawlerTraps A list of crawler trap regular expressions to add
     * to this job.
     */
    private void editOrderXMLAddCrawlerTraps(String elementName,
                                             List<String> crawlerTraps) {
        if (crawlerTraps.size() == 0) {
            return;
        }

        //Get the node to update
        String rulesMapXpath = HeritrixTemplate.DECIDERULES_MAP_XPATH;
        Node rulesMapNode
                = orderXMLdoc.selectSingleNode(rulesMapXpath);
        if (rulesMapNode == null || !(rulesMapNode instanceof Element)) {
            throw new IllegalState(
                    "Unable to update order.xml document."
                    + "It does not have the right form to add"
                    + "crawler trap deciderules.");
        }
        Element rulesMap = (Element) rulesMapNode;

        //Add all regexps in the list to a single MatchesListRegExpDecideRule
        //which is appended to the rulesMapNode.
        Element deciderule = rulesMap.addElement("newObject");
        deciderule.addAttribute("name", elementName);
        deciderule.addAttribute("class",
                MatchesListRegExpDecideRule.class.getName()
            );

        Element decision = deciderule.addElement("string");
        decision.addAttribute("name", "decision");
        decision.addText("REJECT");

        Element listlogic = deciderule.addElement("string");
        listlogic.addAttribute("name", "list-logic");
        listlogic.addText("OR");

        Element regexpList = deciderule.addElement("stringList");
        regexpList.addAttribute("name", "regexp-list");
        for (String trap : crawlerTraps) {
                regexpList.addElement("string").addText(trap);
        }
    }

    /**
     * Tests if a configuration fits into this Job.
     * First tests if it's the right type of order-template and bytelimit, and
     * whether the bytelimit is right for the job.
     * The Job limits are compared against the configuration
     * estimates and if no limits are exceeded true is returned
     * otherwise false is returned.
     *
     * @param cfg the configuration to check
     * @return true if adding the configuration to this Job does
     *         not exceed any of the Job limits.
     * @throws ArgumentNotValid if cfg is null
     */
    public boolean canAccept(DomainConfiguration cfg) {
        ArgumentNotValid.checkNotNull(cfg, "cfg");

        // check if domain in DomainConfiguration cfg is not already in this job
        // domainName is used as key in domainConfigurationMap
        if (domainConfigurationMap.containsKey(cfg.getDomain().getName())) {
            log.debug("Job already has a configuration for Domain '"
                    + cfg.getDomain().getName() +"'.");
            return false;
        }

        // check if template is same as this job.
        if (!orderXMLname.equals(cfg.getOrderXmlName())) {
            log.debug("This Job only accept configurations "
                    + "using the harvest template '" + orderXMLname
                    + "'. This configuration uses the harvest template '"
                    + cfg.getOrderXmlName() + "'.");
            return false;
        }

        // By default byte limit is used as base criterion for splitting a 
        // harvest in config chunks, however the configuration can override this 
        // and instead use object limit.
        boolean splitByObjectLimit = Settings.getBoolean(
                HarvesterSettings.SPLIT_BY_OBJECTLIMIT);
        if (splitByObjectLimit) {
            if (NumberUtils.compareInf(
                    cfg.getMaxObjects(), forceMaxObjectsPerDomain) < 0
                || (configurationSetsObjectLimit
                        && NumberUtils.compareInf(
                                cfg.getMaxObjects(), 
                                forceMaxObjectsPerDomain) != 0)) {
                return false;
            }
        } else {
            if (NumberUtils.compareInf(
                    cfg.getMaxBytes(), forceMaxBytesPerDomain) < 0
                    || (configurationSetsByteLimit
                            && NumberUtils.compareInf(
                                    cfg.getMaxBytes(), 
                                    forceMaxBytesPerDomain) != 0)) {
                return false;
            }
        } 

        assert (maxCountObjects >= minCountObjects) : "basic invariant";

        // The expected number of objects retrieved by this job from
        // the configuration based on historical harvest results.
        long expectation = cfg.getExpectedNumberOfObjects(
                forceMaxObjectsPerDomain,
                forceMaxBytesPerDomain);

        // Check if total count is exceeded
        if ((totalCountObjects > 0)
                && ((expectation + totalCountObjects) > LIM_MAX_TOTAL_SIZE)) {
            return false;
        }

        // total count OK
        // Check if size within existing limits
        if ((expectation <= maxCountObjects)
            && (expectation >= minCountObjects)) {
            // total count ok and within current max and min
            return true;
        }

        // Outside current range we need to check the relative difference
        long absDiff;
        long xmaxCountObjects = maxCountObjects;
        long yminCountObjects = minCountObjects;

        // New max or new min ?
        if (expectation > maxCountObjects) {
            xmaxCountObjects = expectation;
        } else {
            assert (expectation < minCountObjects) : "New minimum expected";
            yminCountObjects = expectation;
        }

        absDiff = (xmaxCountObjects - yminCountObjects);

        if ((absDiff == 0) || (absDiff <= LIM_MIN_ABS_SIZE)) {
            return true; // difference too small to matter
        }

        if (yminCountObjects == 0) {
            yminCountObjects = 1; // make sure division succeeds
        }

        float relDiff = (float) xmaxCountObjects / (float) yminCountObjects;
        if (relDiff > LIM_MAX_REL_SIZE) {
            return false;
        }

        // all tests passed
        return true;
    }

    /**
     * Get the name of the order XML file used by this Job.
     *
     * @return the name of the orderXML file
     */
    public String getOrderXMLName() {
        return orderXMLname;
    }

    /**
     * Get the actual time when this job was stopped/completed.
     *
     * @return the time as Date
     */
    public Date getActualStop() {
        return actualStop;
    }

    /**
     * Get the actual time when this job was started.
     *
     * @return the time as Date
     */
    public Date getActualStart() {
        return actualStart;
    }
    
    /** Get the time when this job was submitted. 
     * @return the time as Date
     */
    public Date getSubmittedDate() {
        return submittedDate;
    }
    

    /**
     * Get a list of Heritrix settings.xml files.
     * Note that these files have nothing to do with NetarchiveSuite settings 
     * files. They are files that supplement the Heritrix order.xml files,
     * and contain overrides for specific domains.
     *
     * @return the list of Files as an array
     */
    public File[] getSettingsXMLfiles() {
        return settingsXMLfiles;
    }

    /**
     * Get the id of the HarvestDefinition from which this job originates.
     *
     * @return the id as a Long
     */
    public Long getOrigHarvestDefinitionID() {
        return origHarvestDefinitionID;
    }

    /**
     * Get the id of this Job.
     *
     * @return the id as a Long
     */
    public Long getJobID() {
        return jobID;
    }

    /**
     * Set the id of this Job.
     *
     * @param id The Id for this job.
     */
    public void setJobID(Long id) {
        jobID = id;
    }

    /**
     * Get's the total number of different domains harvested
     * by this job.
     *
     * @return the number of configurations added to this domain
     */
    public int getCountDomains() {
        return domainConfigurationMap.size();
    }

    /**
     * Set the actual time when this job was started.
     *
     * Sends a notification, if actualStart is set to a
     * time after actualStop.
     * @param actualStart A Date object representing the time
     *                    when this job was started.
     */
    public void setActualStart(Date actualStart) {
        ArgumentNotValid.checkNotNull(actualStart, "actualStart");
        if (actualStop != null && actualStop.before(actualStart)) {
            String errorMsg = "Start time (" + actualStart
            + ") is after end time: " + actualStop;
            log.error(errorMsg);
            NotificationsFactory.getInstance().errorEvent(errorMsg);
        }
        this.actualStart = (Date) actualStart.clone();
    }

    /**
     * Set the actual time when this job was stopped/completed.
     * Sends a notification, if actualStop is set to a
     * time before actualStart.
     * @param actualStop A Date object representing the time
     *                   when this job was stopped.
     */
    public void setActualStop(Date actualStop) {
        ArgumentNotValid.checkNotNull(actualStop, "actualStop");
        if (actualStart == null) {
            String warnMsg = "Value of actualStart is null";
            log.warn(warnMsg);
            NotificationsFactory.getInstance().errorEvent(warnMsg);
        }
        if (actualStart != null && actualStop.before(actualStart)) {
            String errorMsg = "End time (" + actualStop
            + ") is before start time: " + actualStart;
            log.error(errorMsg);
            NotificationsFactory.getInstance().errorEvent(errorMsg);
        }
        this.actualStop = (Date) actualStop.clone();
    }

    public void setOrderXMLDoc(Document doc) {
        ArgumentNotValid.checkNotNull(doc, "doc");
        this.orderXMLdoc = doc;
    }
    
    
    /**
     * Gets a document representation of the order.xml associated with this Job.
     *
     * @return the XML as a org.dom4j.Document
     */
    public Document getOrderXMLdoc() {
        return orderXMLdoc;
    }

    /**
     * Gets a list of document representations of
     * the settings.xml's associated with this Job.
     *
     * @return the XML as an array of org.dom4j.Document
     */
    public Document[] getSettingsXMLdocs() {
        return settingsXMLdocs;
    }

    /**
     * Returns a list of sorted seeds for this job.
     * The sorting is by domain, and inside each domain,
     * the list is sorted by url
     * @return a list of sorted seeds for this job.
     */
    public List<String> getSortedSeedList() {
        Map<String, Set<String>> urlMap = new HashMap<String, Set<String>>();
        for (String seed : seedListSet) {
            String url;
            // Assume the protocol is http://, if it is missing
            if (!seed.matches(Constants.PROTOCOL_REGEXP)) {
                url = "http://" + seed;
            } else {
                url = seed;
            }
            String domain = getDomain(url);
            Set<String> set;
            if (urlMap.containsKey(domain)) {
                set = urlMap.get(domain);
            } else {
                set = new TreeSet<String>();
                urlMap.put(domain, set);
            }
            set.add(seed);

        }
       List<String> result = new ArrayList<String>();
       for (Set<String> set: urlMap.values()) {
           result.addAll(set);
       }
       return result;
    }
    /**
     * Get the domain, that the given URL belongs to.
     * @param url an URL
     * @return the domain, that the given URL belongs to.
     */
    private String getDomain(String url) {
        try {
            URL uri = new URL(url);
            return DomainUtils.domainNameFromHostname(uri.getHost());
        } catch (MalformedURLException e) {
            throw new ArgumentNotValid("The string '" + url
                    + "' is not a valid URL");
        }
    }

    /**
     * Set the seedlist from a seedlist,
     * where the individual seeds are separated by
     * a '\n' character. Duplicate seeds are removed.
     * @param seedList List of seeds as one String
     */
    public void setSeedList(String seedList) {
        //TODO The following is removed, because it breaks a "lot" of unittests.
        // and it has not been checked up until now.
        //ArgumentNotValid.checkNotNullOrEmpty(seedList, "seedList");
        ArgumentNotValid.checkNotNull(seedList, "seedList");
        seedListSet = new HashSet<String>();
        BufferedReader reader = new BufferedReader(new StringReader(seedList));
        String seed;
        try {
            while ((seed = reader.readLine()) != null) {
                seedListSet.add(seed); // add to seedlist if not already there
            }
        } catch (IOException e) {
            // This never happens, as we're reading from a string!
            throw new IOFailure("IOException reading from seed string", e);
        }
        log.debug("Now " + seedListSet.size() + " seeds in the list");
    }

    /**
     * Get the seedlist as a String. The individual seeds are
     * separated by the character '\n'. The order of the seeds are unknown.
     * @return the seedlist as a String
     */
    public String getSeedListAsString() {
        return StringUtils.conjoin("\n", seedListSet);
    }


    /**
     * Get the current status of this Job.
     *
     * @return the status as an int in the range 0 to 4.
     */
    public JobStatus getStatus() {
        return status;
    }

    /**
     * Sets status of this job.
     *
     * @param status Must be one of the values STATUS_NEW, ..., STATUS_FAILED
     * @throws ArgumentNotValid
     *  in case of invalid status argument or invalid status change
     */
    public void setStatus(int status) {
        setStatus(JobStatus.fromOrdinal(status));
    }

    /**
     * Sets status of this job.
     *
     * @param newStatus Must be one of the values STATUS_NEW, ..., STATUS_FAILED
     * @throws ArgumentNotValid
     *  in case of invalid status argument or invalid status change
     */
    public void setStatus(JobStatus newStatus) {
        ArgumentNotValid.checkNotNull(newStatus, "newStatus");
        if (!status.legalChange(newStatus)) {
            final String message = "Status change from " + status
                                + " to " + newStatus + " is not allowed";
            log.debug(message);
            throw new ArgumentNotValid(message);
        }
        if (this.status == JobStatus.SUBMITTED
                && newStatus == JobStatus.STARTED) {
            setActualStart(new Date());
        }
        if (this.status == JobStatus.STARTED
                && (newStatus == JobStatus.DONE
                    || newStatus == JobStatus.FAILED)) {
            setActualStop(new Date());
        }
        status = newStatus;
    }
    /**
     * Returns a map of domain names
     * and name of their corresponding configuration.
     *
     * The returned Map cannot be changed.
     *
     * @return a read-only Map (<String>, <String>)
     */
    public Map<String, String> getDomainConfigurationMap() {
        return Collections.unmodifiableMap(domainConfigurationMap);
    }

    /**
     * Gets the maximum number of objects harvested per domain.
     *
     * @return The maximum number of objects harvested per domain.
     * 0 means no limit.
     */
    public long getMaxObjectsPerDomain() {
        return forceMaxObjectsPerDomain;
    }

    /**
     * Gets the maximum number of bytes harvested per domain.
     *
     * @return The maximum number of bytes harvested per domain.
     *  -1 means no limit.
     */
    public long getMaxBytesPerDomain() {
        return forceMaxBytesPerDomain;
    }

    /**
     * Get the edition number.
     *
     * @return The edition number
     */
    long getEdition() {
        return edition;
    }

    /**
     * Set the edition number.
     *
     * @param edition the new edition number
     */
    void setEdition(long edition) {
        this.edition = edition;
    }
    
    /**
     * toString method for the Job class.
     * @see Object#toString()
     * @return a human readable string representing this object.
     */
    public String toString() {
        return "Job " + getJobID() + " (state = " + getStatus() + ", HD = "
            + getOrigHarvestDefinitionID() + ", priority = " + getPriority()
            + ", forcemaxcount = " + getForceMaxObjectsPerDomain()
            + ", forcemaxbytes = " + getMaxBytesPerDomain()
            + ", orderxml = " + getOrderXMLName()
            + ", numconfigs = " + getDomainConfigurationMap().size()
            + ")";
    }

    /**
     * @return Returns the forceMaxObjectsPerDomain. 0 means no limit.
     */
    long getForceMaxObjectsPerDomain() {
        return forceMaxObjectsPerDomain;
    }

    /**
     * Sets the maxObjectsPerDomain value.
     * @param forceMaxObjectsPerDomain The forceMaxObjectsPerDomain to set.
     * 0 means no limit.
     * @throws IOFailure
     *  Thrown from auxiliary method editOrderXML_maxObjectsPerDomain.
     */
    private void setForceMaxObjectsPerDomain(long forceMaxObjectsPerDomain) {
        if (!underConstruction) {
            final String msg = "Cannot modify job "
                    + this + " as it is no longer under construction";
            log.debug(msg);
            throw new IllegalState(msg);
        }
        this.forceMaxObjectsPerDomain = forceMaxObjectsPerDomain;
        editOrderXML_maxObjectsPerDomain(forceMaxObjectsPerDomain);
    }

    /**
     * Set the maxbytes per domain value.
     * @param maxBytesPerDomain The maxBytesPerDomain to set,
     *                          or -1 for no limit.
     */
    private void setMaxBytesPerDomain(long maxBytesPerDomain) {
        if (!underConstruction) {
            final String msg = "Cannot modify job "
                    + this + " as it is no longer under construction";
            log.debug(msg);
            throw new IllegalState(msg);
        }
        this.forceMaxBytesPerDomain = maxBytesPerDomain;
        editOrderXML_maxBytesPerDomain(maxBytesPerDomain);
    }

    /**
     * Auxiliary method to modify the orderXMLdoc Document
     * with respect to setting the maximum number of objects to be retrieved
     * per domain.
     * This method updates 'group-max-fetch-success' element of the QuotaEnforcer
     * pre-fetch processor snode
     * (org.archive.crawler.frontier.BdbFrontier)
     * with the value of the argument forceMaxObjectsPerDomain
     *
     * @param forceMaxObjectsPerDomain
     *           The maximum number of objects to retrieve per domain, or 0
     *           for no limit.
     * @throws PermissionDenied
     *           If unable to replace the frontier node of
     *           the orderXMLdoc Document
     * @throws IOFailure
     *           If the group-max-fetch-success element is not found in the orderXml.
     * TODO The group-max-fetch-success check should also be performed in
     * TemplateDAO.create, TemplateDAO.update
     */
    private void editOrderXML_maxObjectsPerDomain(
            long forceMaxObjectsPerDomain) {
              
        String xpath = HeritrixTemplate.GROUP_MAX_FETCH_SUCCESS_XPATH;
        Node groupMaxFectResponsesNode = orderXMLdoc.selectSingleNode(xpath);
        if (groupMaxFectResponsesNode != null) {
            groupMaxFectResponsesNode.setText(
                    String.valueOf(forceMaxObjectsPerDomain));            
        } else {
            throw new IOFailure(
                    "Unable to locate " 
                    +  HeritrixTemplate.GROUP_MAX_FETCH_SUCCESS_XPATH
                    + " element in order.xml: "
                    + orderXMLdoc.asXML());
        }
    }

    /**
     * Auxiliary method to modify the orderXMLdoc Document
     * with respect to setting the maximum number of bytes to retrieve
     * per domain. This method updates 'group-max-all-kb' element of
     * the 'QuotaEnforcer' node,
     * which again is a subelement of 'pre-fetch-processors' node.
     * with the value of the argument forceMaxBytesPerDomain
     *
     * @param forceMaxBytesPerDomain
     *      The maximum number of byte to retrieve per domain,
     *      or -1 for no limit.
     *      Note that the number is divided by 1024 before being inserted into
     *      the orderXml, as Heritrix expects KB.
     * @throws PermissionDenied
     *      If unable to replace the QuotaEnforcer node of the
     *      orderXMLdoc Document
     * @throws IOFailure
     *      If the group-max-all-kb element cannot be found.
     * TODO This group-max-all-kb check also be performed in
     * TemplateDAO.create, TemplateDAO.update
     */
    private void editOrderXML_maxBytesPerDomain(long forceMaxBytesPerDomain) {
        // get and set the group-max-all-kb Node of the orderXMLdoc:
        String xpath = HeritrixTemplate.GROUP_MAX_ALL_KB_XPATH;
        Node groupMaxSuccessKbNode = orderXMLdoc.selectSingleNode(xpath);
        if (groupMaxSuccessKbNode != null) {
            if (forceMaxBytesPerDomain != Constants.HERITRIX_MAXBYTES_INFINITY)
            {
                // Divide by 1024 since Heritrix uses KB rather than bytes,
                // and add 1 to avoid to low limit due to rounding.
                groupMaxSuccessKbNode.setText(
                        Long.toString((forceMaxBytesPerDomain
                                       / BYTES_PER_HERITRIX_BYTELIMIT_UNIT)
                                      + 1)
                );
            } else {
                groupMaxSuccessKbNode.setText(
                        String.valueOf(Constants.HERITRIX_MAXBYTES_INFINITY));
            }
        } else {
            throw new IOFailure(
                    "Unable to locate QuotaEnforcer object in order.xml: "
                    + orderXMLdoc.asXML());
        }
    }

    /**
     * Get the priority of this job.
     *
     * @return The priority. The return values can only be one of
     *         the priorities defined above: LOWPRIORITY and HIGHPRIORITY
     */
    public JobPriority getPriority() {
        return priority;
    }

    /**
     * Invoke default method for deserializing object, and reinitialise the
     * logger.
     *
     * @param s stream with serialized object.
     */
    private void readObject(ObjectInputStream s) {
        try {
            s.defaultReadObject();
        } catch (Exception e) {
            throw new IOFailure("Unexpected error during deserialization", e);
        }
        log = LogFactory.getLog(getClass());
    }

    /**
     * Invoke default method for serializing object.
     *
     * @param s stream to serialize object to.
     */
    private void writeObject(ObjectOutputStream s) {
        try {
            s.defaultWriteObject();
        } catch (Exception e) {
            throw new IOFailure("Unexpected error during serialization", e);
        }
    }

    /**
     * Get the harvestNum for this job.
     * The number reflects which run of the harvest definition this is.
     * @return the harvestNum for this job.
     */
    public int getHarvestNum() {
        return harvestNum;
    }

    /**
     * Set the harvestNum for this job.
     * The number reflects which run of the harvest definition this is.
     * ONLY TO BE USED IN THE CONSTRUCTION PHASE.
     * @param harvestNum a given harvestNum
     */
    public void setHarvestNum(int harvestNum) {
        if (!underConstruction) {
            final String msg = "Cannot modify job "
                    + this + " as it is no longer under construction";
            log.debug(msg);
            throw new IllegalState(msg);
        }
        this.harvestNum = harvestNum;
    }

    /**
     * Get the list of harvest errors for this job.
     * If no harvest errors, null is returned
     * This value is not meaningful until the job is finished
     * (FAILED,DONE, RESUBMITTED)
     * @return the harvest errors for this job or null if no harvest errors.
     */
    public String getHarvestErrors() {
        return harvestErrors;
    }

    /**
     * Append to the list of harvest errors for this job.
     * Nothing happens, if argument harvestErrors is null.
     * @param harvestErrors a string containing harvest errors (may be null)
     */
    public void appendHarvestErrors(String harvestErrors) {
        if (harvestErrors != null) {
            if (this.harvestErrors == null) {
                this.harvestErrors = harvestErrors;
            } else {
                this.harvestErrors += "\n" + harvestErrors;
            }
        }
    }

    /**
     * Get the list of harvest error details for this job.
     * If no harvest error details, null is returned
     * This value is not meaningful until the job is finished
     * (FAILED,DONE, RESUBMITTED)
     * @return the list of harvest error details for this job
     *  or null if no harvest error details.
     */

    public String getHarvestErrorDetails() {
        return harvestErrorDetails;
    }

    /**
     * Append to the list of harvest error details for this job.
     * Nothing happens, if argument harvestErrorDetails is null.
     *
     * @param harvestErrorDetails a string containing harvest error details.
     */
    public void appendHarvestErrorDetails(String harvestErrorDetails) {
        if (harvestErrorDetails != null) {
            if (this.harvestErrorDetails == null) {
                this.harvestErrorDetails = harvestErrorDetails;
            } else {
                this.harvestErrorDetails += "\n" + harvestErrorDetails;
            }
        }
    }

    /**
     * Get the list of upload errors.
     * If no upload errors, null is returned.
     * This value is not meaningful until the job is finished
     * (FAILED,DONE, RESUBMITTED)
     * @return the list of upload errors as String,
     *  or null if no upload errors.
     */
    public String getUploadErrors() {
        return uploadErrors;
    }

    /**
     * Append to the list of upload errors.
     * Nothing happens, if argument uploadErrors is null.
     * @param uploadErrors a string containing upload errors.
     */
    public void appendUploadErrors(String uploadErrors) {
        if (uploadErrors != null) {
            if (this.uploadErrors == null) {
                this.uploadErrors = uploadErrors;
            } else {
                this.uploadErrors += "\n" + uploadErrors;
            }
        }
    }

    /**
     * Get the list of upload error details.
     * If no upload error details, null is returned.
     * This value is not meaningful until the job is finished
     * (FAILED,DONE, RESUBMITTED)
     * @return the list of upload error details as String,
     *  or null if no upload error details
     */
    public String getUploadErrorDetails() {
        return uploadErrorDetails;
    }

    /**
     * Append to the list of upload error details.
     * Nothing happens, if argument uploadErrorDetails is null.
     * @param uploadErrorDetails a string containing upload error details.
     */
    public void appendUploadErrorDetails(String uploadErrorDetails) {
        if (uploadErrorDetails != null) {
            if (this.uploadErrorDetails == null) {
                this.uploadErrorDetails = uploadErrorDetails;
            } else {
                this.uploadErrorDetails += "\n" + uploadErrorDetails;
            }
        }
    }

    /**
     * Get a list of AliasInfo objects for all the domains included in the job.
     * @return a list of AliasInfo objects for all the domains included in the
     * job.
     */
    public List<AliasInfo> getJobAliasInfo() {
        List<AliasInfo> aliases = new ArrayList<AliasInfo>();
        DomainDAO dao = DomainDAO.getInstance();
        for (String domain : getDomainConfigurationMap().keySet()) {
            aliases.addAll(dao.getAliases(domain));
        }
        return aliases;
    }

    /**
     * Get the ID for the job which this job was resubmitted as.
     * If null, this job has not been resubmitted.
     * @return this ID.
     */
    public Long getResubmittedAsJob() {
        return resubmittedAsJobWithID;
    }

    /**
     * Set the Date for when this job was submitted.
     * If null, this job has not been submitted.
     * @param submittedDate The date when this was submitted
     */
    public void setSubmittedDate(Date submittedDate) {
        this.submittedDate = submittedDate;
    }

    /**
     * Set the ID for the job which this job was resubmitted as.
     * @param resubmittedAsJob An Id for a new job.
     */
    public void setResubmittedAsJob(Long resubmittedAsJob) {
        this.resubmittedAsJobWithID = resubmittedAsJob;
        
    }
}
