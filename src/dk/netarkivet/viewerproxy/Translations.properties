#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
# File:        $Id$
# Revision:    $Revision$
# Author:      $Author$
# Date:        $Date$
#
# The Netarchive Suite - Software to harvest and preserve websites
# Copyright 2004-2010 Det Kongelige Bibliotek and Statsbiblioteket, Denmark
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA

browsing.jobs.in.viewerproxy = Browsing jobs in the viewerproxy

clear.collected.urls = Clear collected URLs

current.list.contains.0.urls  = Current list of missing URLs contains {0,number, integer} URLs.
current.viewerproxy.status    = Current Viewerproxy status:

currently.collecting.urls     = Currently collects missing URLs.
currently.not.collecting.urls = Currently does _not_ collect missing URLs.

errormsg;request.was.for.0.but.got.1.missing.2 = WARNING: The request was for the jobs {0}, but only the jobs {1} had available data for the index. Missing data for the jobs {2}

generating.index.0.for.jobs.1 = Generating index ''{0}'' for jobs [{1}]

helptext;get.job.qa.information.with.viewerproxy = The links below will only work if your browser is set up to use the viewerproxy as web proxy.

helptext;qa.statusbox.explanation = If the frame is empty, either the viewerproxy hasn't been started, or your web browser has not been configured to use it.

index.0.built.on.jobs.1 = Using index ''{0}'', built on jobs: {1}.

missing.urls = Missing URL collection

no.index.set = No jobs have been chosen for viewerproxy index.

pagetitle;files.for.job.0 = Files for job {0}

pagetitle;qa.crawllog.lines.for.domain                  = Lines from crawl.log about domain
pagetitle;qa.crawllog.lines.for.domain.0.in.1           = Lines from crawl.log of job {1} concerning domain {0}
pagetitle;qa.crawllog.lines.for.job.0.matching.regexp.1 = Lines from crawl.log of job {0} matching the regular expression {1}
pagetitle;qa.crawllog.lines.matching.regexp             = Lines from crawl.log matching regular expression
pagetitle;qa.get.files                                  = Get harvested files
pagetitle;qa.get.reports                                = Get harvest reports
pagetitle;qa.status                                     = Viewerproxy Status

pagetitle;reports.for.job.1 = Reports for job {0}

redirecting = Redirecting

selective.harvest.history = Selective harvest history

show.collected.urls = Show collected URLs

sitesection;qa = Quality Assurance

snapshot.harvest.history = Snapshot harvest history

start.collecting.urls = Start collecting URLs

stop.collecting.urls = Stop collecting URLs

use.these.pages.for.viewerproxy.job.selection = Use these pages to select the index for viewerproxy browsing:
